{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.gaussian_process as gp\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from PredictXANES import xanes_derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    '''\n",
    "    The spectra are split into a training set and \n",
    "    testing set with a ratio of 4:1. The predicted features are the coordination number, \n",
    "    number of Cu atoms, and number of Te atoms.\n",
    "    '''\n",
    "    \n",
    "    X = df.drop(labels=['CN', 'Num Cu', 'Num Te'], axis=1)\n",
    "    list = X.columns.tolist()\n",
    "\n",
    "    X.columns = range(X.shape[1])\n",
    "   \n",
    "    y = df[['CN', 'Num Cu', 'Num Te']]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=519)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, X, y\n",
    "\n",
    "def derivatives(X_noise):\n",
    "    '''\n",
    "    derivatives returns the first, second, and combined first and second derivitive dataframes\n",
    "    '''\n",
    "    d1, d2 = xanes_derivatives.xanes_derivatives(X)\n",
    "    df1 = pd.DataFrame(d1)\n",
    "    df2 = pd.DataFrame(d2)\n",
    "    df3 = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    return df1, df2, df3\n",
    "    \n",
    "def train(X_train, y_train):\n",
    "    '''\n",
    "    train_layer trains the neural network. One layer is added, and the depth of the that layer is optimized by \n",
    "    looking at the loss from a range of 1 to 100, the maximum number of features being trained on.\n",
    "    '''\n",
    "    \n",
    "    loss = []\n",
    "    for i in range(100):\n",
    "        if i == 0:\n",
    "            pass\n",
    "        else:\n",
    "            nn = MLPRegressor(hidden_layer_sizes=(i), activation='identity', solver='lbfgs', max_iter=2000, random_state=28)\n",
    "            nn = nn.fit(X_train, y_train)\n",
    "            loss.append(nn.loss_)\n",
    "\n",
    "    lossdf = pd.DataFrame(loss)\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        print(lossdf)\n",
    "    return lossdf, nn\n",
    "\n",
    "def analyse_layer(X_train, X_test, y_train, y_test, nn):\n",
    "    '''\n",
    "    analyse_layer returns the training mse and r2 values for the layer in the neural network\n",
    "    '''\n",
    "    \n",
    "    y_train_pred = nn.predict(X_train)\n",
    "    y_test_pred = nn.predict(X_test)\n",
    "    train_score_CN = r2_score(y_train.iloc[:,0], y_train_pred[:,0])\n",
    "    train_score_Cu = r2_score(y_train.iloc[:,1], y_train_pred[:,1]) \n",
    "    train_score_Te = r2_score(y_train.iloc[:,2], y_train_pred[:,2])\n",
    "    test_score_CN = r2_score(y_test.iloc[:,0], y_test_pred[:,0])\n",
    "    test_score_Cu = r2_score(y_test.iloc[:,1], y_test_pred[:,1])\n",
    "    test_score_Te = r2_score(y_test.iloc[:,2], y_test_pred[:,2])\n",
    "    train_mse_CN = mean_squared_error(y_train.iloc[:,0], y_train_pred[:,0])\n",
    "    train_mse_Cu = mean_squared_error(y_train.iloc[:,1], y_train_pred[:,1])\n",
    "    train_mse_Te = mean_squared_error(y_train.iloc[:,2], y_train_pred[:,2])\n",
    "    test_mse_CN = mean_squared_error(y_test.iloc[:,0], y_test_pred[:,0])\n",
    "    test_mse_Cu = mean_squared_error(y_test.iloc[:,1], y_test_pred[:,1])\n",
    "    test_mse_Te = mean_squared_error(y_test.iloc[:,2], y_test_pred[:,2])\n",
    "\n",
    "    train_score_list = [train_score_CN, train_score_Cu, train_score_Te]\n",
    "    train_mse_list = [train_mse_CN, train_mse_Cu, train_mse_Te]\n",
    "    test_mse_list = [test_mse_CN, train_mse_Cu, train_mse_Te]\n",
    "    test_score_list = [test_score_CN, test_score_Cu, test_score_Te]\n",
    "    print('training mse =  '+ str(train_mse_list))\n",
    "    print('testing mse = ' + str(test_mse_list))\n",
    "    print('training R2 = ' + str(train_score_list))\n",
    "    print('testing R2 = ' + str(test_score_list))\n",
    "    \n",
    "    return test_mse_list, test_score_list, y_test_pred\n",
    "\n",
    "def append_layer_to_list(test_mse_list, test_score_list, rmse_CN_master_list, score_CN_master_list, rmse_Cu_master_list, score_Cu_master_list, rmse_Te_master_list, score_Te_master_list):\n",
    "    '''\n",
    "    append_layer_to_list takes the mse and score lists and appends them to a list for plotting erros vs noise, \n",
    "    note that here mse is converted to rmse\n",
    "    '''\n",
    "    \n",
    "    rmse_CN = np.sqrt(test_mse_list[0])\n",
    "    rmse_CN_master_list.append(rmse_CN)\n",
    "    rmse_Cu = np.sqrt(test_mse_list[1])\n",
    "    rmse_Cu_master_list.append(rmse_Cu)\n",
    "    rmse_Te = np.sqrt(test_mse_list[2])\n",
    "    rmse_Te_master_list.append(rmse_Te)\n",
    "    \n",
    "    score_CN = test_score_list[0]\n",
    "    score_CN_master_list.append(score_CN)\n",
    "    score_Cu = test_score_list[1]\n",
    "    score_Cu_master_list.append(score_Cu)\n",
    "    score_Te = test_score_list[2]\n",
    "    score_Te_master_list.append(score_Te)\n",
    "\n",
    "def plot_parity(y_test, y_test_pred):\n",
    "    '''\n",
    "    plot_parity is a function to generate parity plots for the layer to check performance for predicting \n",
    "    coordination number, number of nearest Te atoms, and number of nearest Cu atoms.\n",
    "    '''\n",
    "    x1 = np.linspace(8, 12, 50)\n",
    "    x2 = np.linspace(4, 8, 50)\n",
    "    x3 = np.linspace(4, 5, 50)\n",
    "\n",
    "    plt.figure(figsize=[14,4])\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    ax1 = plt.subplot(1,3,1)\n",
    "    ax1.scatter(y_test.iloc[:,0], y_test_pred[:,0])\n",
    "    ax1.plot(x1, x1, color='red')\n",
    "    ax1.set_xlabel('True CN')\n",
    "    ax1.set_ylabel('Pred CN')\n",
    "    ax1.set_title('Test CN')\n",
    "    plt.axis('equal')\n",
    "\n",
    "    ax2 = plt.subplot(1,3,2)\n",
    "    ax2.scatter(y_test.iloc[:,1], y_test_pred[:,1])\n",
    "    ax2.plot(x2, x2, color='red')\n",
    "    ax2.set_xlabel('True Cu Num')\n",
    "    ax2.set_ylabel('Pred Cu Num')\n",
    "    ax2.set_title('Test Cu Num')\n",
    "    plt.axis('equal')\n",
    "\n",
    "\n",
    "    ax3 = plt.subplot(1,3,3)\n",
    "    ax3.scatter(y_test.iloc[:,2], y_test_pred[:,2])\n",
    "    ax3.plot(x3, x3, color='red')\n",
    "    ax3.set_xlabel('True Te Num')\n",
    "    ax3.set_ylabel('Pred Te Num')\n",
    "    ax3.set_title('Test Te Num')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    \n",
    "def run_layer(X_train, X_test, y_train, y_test, rmse_CN_master_list, score_CN_master_list, rmse_Cu_master_list, score_Cu_master_list, rmse_Te_master_list, score_Te_master_list):\n",
    "    '''\n",
    "    run_layer is a wrapper function that executes the training, testing, analysis, and plotting for a \n",
    "    single layer of the neural network\n",
    "    '''\n",
    "    lossdf, nn = train(X_train, y_train)\n",
    "    test_mse_list, test_score_list, y_test_pred = analyse_layer(X_train, X_test, y_train, y_test, nn) #series from dataframe\n",
    "    append_layer_to_list(test_mse_list, test_score_list, rmse_CN_master_list, score_CN_master_list, rmse_Cu_master_list, score_Cu_master_list, rmse_Te_master_list, score_Te_master_list)\n",
    "    plot_parity(y_test, y_test_pred)\n",
    "\n",
    "def MLP_per_set_size(df, Noise_STD, rmse_CN_master_list, score_CN_master_list, rmse_Cu_master_list, score_Cu_master_list, rmse_Te_master_list, score_Te_master_list):\n",
    "    '''\n",
    "    MLP_per_noise is a wrapper function that runs a layer of neural network per level of noise\n",
    "    '''\n",
    "    for entry in Noise_STD:\n",
    "        X_train, X_test, y_train, y_test, X, y = split_data(df)\n",
    "        run_layer(X_train, X_test, y_train, y_test, rmse_CN_master_list, score_CN_master_list, rmse_Cu_master_list, score_Cu_master_list, rmse_Te_master_list, score_Te_master_list)\n",
    "    print(rmse_CN_master_list, score_CN_master_list, rmse_Cu_master_list, score_Cu_master_list, rmse_Te_master_list, score_Te_master_list)\n",
    "\n",
    "def MLP_per_set_size_1(df, set_size, rmse_CN_master_list_1, score_CN_master_list_1, rmse_Cu_master_list_1, score_Cu_master_list_1, rmse_Te_master_list_1, score_Te_master_list_1):\n",
    "    for entry in set_size:\n",
    "        _, _, _, _, X, y = split_data(df, entry)\n",
    "        df1, df2, df3, = derivatives(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df1, y)\n",
    "        run_layer(X_train, X_test, y_train, y_test, rmse_CN_master_list_1, score_CN_master_list_1, rmse_Cu_master_list_1, score_Cu_master_list_1, rmse_Te_master_list_1, score_Te_master_list_1)\n",
    "    print(rmse_CN_master_list_1, score_CN_master_list_1, rmse_Cu_master_list_1, score_Cu_master_list_1, rmse_Te_master_list_1, score_Te_master_list_1)\n",
    "\n",
    "def MLP_per_set_size_2(df, set_size, rmse_CN_master_list_2, score_CN_master_list_2, rmse_Cu_master_list_2, score_Cu_master_list_2, rmse_Te_master_list_2, score_Te_master_list_2):\n",
    "    for entry in set_size:\n",
    "        _, _, _, _, X, y = split_data(df, entry)\n",
    "        df1, df2, df3, = derivatives(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df2, y)\n",
    "        run_layer(X_train, X_test, y_train, y_test, rmse_CN_master_list_2, score_CN_master_list_2, rmse_Cu_master_list_2, score_Cu_master_list_2, rmse_Te_master_list_2, score_Te_master_list_2)\n",
    "    print(rmse_CN_master_list_2, score_CN_master_list_2, rmse_Cu_master_list_2, score_Cu_master_list_2, rmse_Te_master_list_2, score_Te_master_list_2)\n",
    "    \n",
    "    \n",
    "def MLP_per_set_size_1_2(df, Noise_STD, rmse_CN_master_list_1_2, score_CN_master_list_1_2, rmse_Cu_master_list_1_2, score_Cu_master_list_1_2, rmse_Te_master_list_1_2, score_Te_master_list_1_2):\n",
    "    for entry in set_size:\n",
    "        _, _, _, _, X, y = split_data(df, entry)\n",
    "        df1, df2, df3, = derivatives(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df3, y)\n",
    "        run_layer(X_train, X_test, y_train, y_test, rmse_CN_master_list_1_2, score_CN_master_list_1_2, rmse_Cu_master_list_1_2, score_Cu_master_list_1_2, rmse_Te_master_list_1_2, score_Te_master_list_1_2)\n",
    "    print(rmse_CN_master_list_1_2, score_CN_master_list_1_2, rmse_Cu_master_list_1_2, score_Cu_master_list_1_2, rmse_Te_master_list_1_2, score_Te_master_list_1_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data import of 10,000 calculated average XANES spectra along with averaged coordination numbers, number of Cu atoms within 3 angstroms, and number of Te atoms within 3 angstroms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mu_cn10000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectra Only:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists for plotting noise vs R2 an RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise_STD = [0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05]\n",
    "rmse_CN_master_list = []\n",
    "score_CN_master_list = []\n",
    "rmse_Cu_master_list = []\n",
    "score_Cu_master_list = []\n",
    "rmse_Te_master_list = []\n",
    "score_Te_master_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_per_set_size(df, Noise_STD, rmse_CN_master_list, score_CN_master_list, rmse_Cu_master_list, score_Cu_master_list, rmse_Te_master_list, score_Te_master_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated for training with first derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise_STD = [0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05]\n",
    "rmse_CN_master_list_1 = []\n",
    "score_CN_master_list_1 = []\n",
    "rmse_Cu_master_list_1 = []\n",
    "score_Cu_master_list_1 = []\n",
    "rmse_Te_master_list_1 = []\n",
    "score_Te_master_list_1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_per_noise_1(df, Noise_STD, rmse_CN_master_list_1, score_CN_master_list_1, rmse_Cu_master_list_1, score_Cu_master_list_1, rmse_Te_master_list_1, score_Te_master_list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated for training with both the first and second derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise_STD = [0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05]\n",
    "rmse_CN_master_list_1_2 = []\n",
    "score_CN_master_list_1_2 = []\n",
    "rmse_Cu_master_list_1_2 = []\n",
    "score_Cu_master_list_1_2 = []\n",
    "rmse_Te_master_list_1_2 = []\n",
    "score_Te_master_list_1_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_per_noise_1_2(df, Noise_STD, rmse_CN_master_list_1_2, score_CN_master_list_1_2, rmse_Cu_master_list_1_2, score_Cu_master_list_1_2, rmse_Te_master_list_1_2, score_Te_master_list_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_CN_master_list_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Noise_STD = [0, 0.005, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045, 0.05]\n",
    "rmse_CN_master_list_2 = []\n",
    "score_CN_master_list_2 = []\n",
    "rmse_Cu_master_list_2 = []\n",
    "score_Cu_master_list_2 = []\n",
    "rmse_Te_master_list_2 = []\n",
    "score_Te_master_list_2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_per_noise_2(df, Noise_STD, rmse_CN_master_list_2, score_CN_master_list_2, rmse_Cu_master_list_2, score_Cu_master_list_2, rmse_Te_master_list_2, score_Te_master_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_CN_master_list_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[12,5])\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "ax1.plot(Noise_STD, score_CN_master_list, c='blue', lw=2.5, label='Spectrum')\n",
    "ax1.plot(Noise_STD, score_CN_master_list_1, c='red', lw=2.5, label='First Derivative')\n",
    "ax1.plot(Noise_STD, score_CN_master_list_2, c='darkorange', lw=2.5, label='Second Derivative')\n",
    "ax1.plot(Noise_STD, score_CN_master_list_1_2, c='green', lw=2.5, label='Both Derivatives')\n",
    "ax1.set_xlabel('Noise standard deviation (%)', fontsize=16)\n",
    "ax1.set_ylabel('$R^2$', fontsize=16)\n",
    "ax2.plot(Noise_STD, rmse_CN_master_list, c='blue', lw=2.5)\n",
    "ax2.plot(Noise_STD, rmse_CN_master_list_1, c='red', lw=2.5)\n",
    "ax2.plot(Noise_STD, rmse_CN_master_list_2, c='darkorange', lw=2.5)\n",
    "ax2.plot(Noise_STD, rmse_CN_master_list_1_2, c='green', lw=2.5)\n",
    "ax2.set_xlabel('Noise standard deviation (%)', fontsize=16)\n",
    "ax2.set_ylabel('RMSE', fontsize=16)\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[12,5])\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "ax1.plot(Noise_STD, score_Cu_master_list, c='blue', lw=2.5, label='Spectrum')\n",
    "ax1.plot(Noise_STD, score_Cu_master_list_1, c='red', lw=2.5, label='First Derivative')\n",
    "ax1.plot(Noise_STD, score_Cu_master_list_2, c='darkorange', lw=2.5, label='Second Derivative')\n",
    "ax1.plot(Noise_STD, score_Cu_master_list_1_2, c='green', lw=2.5, label='Both Derivatives')\n",
    "ax1.set_xlabel('Noise standard deviation (%)', fontsize=16)\n",
    "ax1.set_ylabel('$R^2$', fontsize=16)\n",
    "ax2.plot(Noise_STD, rmse_Cu_master_list, c='blue', lw=2.5)\n",
    "ax2.plot(Noise_STD, rmse_Cu_master_list_1, c='red', lw=2.5)\n",
    "ax2.plot(Noise_STD, rmse_Cu_master_list_2, c='darkorange', lw=2.5)\n",
    "ax2.plot(Noise_STD, rmse_Cu_master_list_1_2, c='green', lw=2.5)\n",
    "ax2.set_xlabel('Noise standard deviation (%)', fontsize=16)\n",
    "ax2.set_ylabel('RMSE', fontsize=16)\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=[12,5])\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "ax1.plot(Noise_STD, score_Te_master_list, c='blue', lw=2.5, label='Spectrum')\n",
    "ax1.plot(Noise_STD, score_Te_master_list_1, c='red', lw=2.5, label='First Derivative')\n",
    "ax1.plot(Noise_STD, score_Te_master_list_2, c='darkorange', lw=2.5, label='Second Derivative')\n",
    "ax1.plot(Noise_STD, score_Te_master_list_1_2, c='green', lw=2.5, label='Both Derivatives')\n",
    "ax1.set_xlabel('Noise standard deviation (%)', fontsize=16)\n",
    "ax1.set_ylabel('$R^2$', fontsize=16)\n",
    "ax2.plot(Noise_STD, rmse_Te_master_list, c='blue', lw=2.5)\n",
    "ax2.plot(Noise_STD, rmse_Te_master_list_1, c='red', lw=2.5)\n",
    "ax2.plot(Noise_STD, rmse_Te_master_list_2, c='darkorange', lw=2.5)\n",
    "ax2.plot(Noise_STD, rmse_Te_master_list_1_2, c='green', lw=2.5)\n",
    "ax2.set_xlabel('Noise standard deviation (%)', fontsize=16)\n",
    "ax2.set_ylabel('RMSE', fontsize=16)\n",
    "ax1.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
